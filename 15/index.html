<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Machine Learning Fundamentals, Part 2 with Shannon Wirtz - Compiled Conversations</title>
<meta name=description content="We continue our conversation with Shannon Wirtz, diving into ensemble methods, neural networks (including CNNs, RNNs, and Transformers), model training and evaluation techniques, interpretation methods, and practical learning resources for those getting started with ML."><link rel="stylesheet" href="/css/main.016fc070c1482260051203082aaae382bb211da015a29e6b78e8615d2b9bc88c.css" integrity="sha256-AW/AcMFIImAFEgMIKqrjgrshHaAVop5reOhhXSubyIw=" crossorigin="anonymous" />
<link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon-180x180.png><link rel=icon type=image/png sizes=32x32 href=/icons/favicon-32x32.png><link rel=icon type=image/png sizes=96x96 href=/icons/favicon-96x96.png><link rel=icon type=image/png sizes=16x16 href=/icons/favicon-16x16.png></head><body class="bg-white font-body"><div class="pt-16 pb-20 px-4 sm:px-6 lg:pt-24 lg:pb-28 lg:px-8"><div class="relative max-w-2xl mx-auto"><header><div class="flex flex-col items-center space-y-8 sm:items-center sm:space-y-0 sm:flex-row sm:space-x-8"><a class=flex-shrink-0 href=https://compiledconversations.com/ aria-label="Go to Compiled Conversations homepage"><span class=sr-only>Compiled Conversations</span>
<img class="h-28 w-28 sm:h-36 sm:w-36 rounded-lg object-cover" src=https://compiledconversations.com/album-art.jpg alt="Compiled Conversations"></a><div class="text-center sm:text-left"><h2 class="text-3xl leading-9 tracking-tight font-extrabold text-gray-900 sm:text-4xl sm:leading-10 font-heading"><a href=https://compiledconversations.com/>Compiled Conversations</a></h2><div class=mt-2><p class="text-xl leading-7 text-gray-500">Conversations with the people shaping software and technology. Hosted by
<a href=https://eddmann.com target=_blank>Edd Mann</a>.</p></div><nav class=mt-4 aria-label="Podcast platforms"><ul class="flex justify-center space-x-2 text-gray-400 sm:justify-start list-none"><li><a class="text-gray-600 hover:text-gray-900" href=https://podcasts.apple.com/us/podcast/compiled-conversations/id1828390930 target=_blank aria-label="Listen on Apple Podcasts">Apple Podcasts</a></li><li><span aria-hidden=true>•</span></li><li><a class="text-gray-600 hover:text-gray-900" href=https://open.spotify.com/show/4qErnd7sQYM556ntaLSKfx target=_blank aria-label="Listen on Spotify">Spotify</a></li><li><span aria-hidden=true>•</span></li><li><a class="text-gray-600 hover:text-gray-900" href=/rss.xml target=_blank aria-label="Subscribe to RSS feed">RSS</a></li></ul></nav></div></div></header><main class="border-t-2 border-gray-100 pt-8 mt-7 mb-7" role=main><article><header><p class="text-sm leading-5 text-gray-500"><time datetime=2025-11-21>Nov 21, 2025</time></p><h1 class="mt-2 text-xl leading-7 font-semibold text-gray-900 font-heading">Machine Learning Fundamentals, Part 2 with Shannon Wirtz</h1></header><section aria-label="Audio player"><div class="audio-player my-8 w-full bg-gray-100 rounded-lg p-4 shadow" data-src=https://podcasts.compiledconversations.com/015-machine-learning-fundamentals-part-2-with-shannon-wirtz.mp3 data-duration=4023><div class="flex items-center space-x-4"><button class="play-pause p-3 bg-teal-600 text-white rounded-full focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-teal-500" aria-label="Play or pause episode" type=button>
<svg class="icon-play h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14.752 11.168 9.555 8.14A1 1 0 008 8.94v6.12a1 1 0 001.555.832l5.197-3.028a1 1 0 000-1.664z"/></svg>
<svg class="icon-pause h-6 w-6 hidden" fill="none" viewBox="0 0 24 24" stroke="currentcolor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 9v6m4-6v6"/></svg>
</button>
<span class="current-time text-sm font-mono w-12" aria-label="Current time">00:00</span>
<input type=range class="seek flex-1 h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer" min=0 value=0 aria-label="Seek through episode">
<span class="duration text-sm font-mono w-12" aria-label="Total duration">67:03</span></div></div></section><script>function formatTime(e){const t=Math.floor(e/60).toString().padStart(2,"0"),n=Math.floor(e%60).toString().padStart(2,"0");return`${t}:${n}`}function initAudioPlayers(){document.querySelectorAll(".audio-player").forEach(e=>{const r=e.dataset.src;let t=null;const s=e.querySelector(".play-pause"),o=s.querySelector(".icon-play"),i=s.querySelector(".icon-pause"),a=e.querySelector(".current-time"),c=e.querySelector(".duration"),n=e.querySelector(".seek");function l(){if(t!==null)return;t=new Audio(r),t.addEventListener("loadedmetadata",()=>{const e=Math.floor(t.duration);c.textContent=formatTime(e),n.max=e}),t.addEventListener("timeupdate",()=>{a.textContent=formatTime(t.currentTime),n.value=Math.floor(t.currentTime)}),t.addEventListener("ended",()=>{i.classList.add("hidden"),o.classList.remove("hidden"),a.textContent="00:00",n.value=0})}s.addEventListener("click",()=>{t===null&&l(),t.paused?(t.play(),o.classList.add("hidden"),i.classList.remove("hidden")):(t.pause(),i.classList.add("hidden"),o.classList.remove("hidden"))}),n.addEventListener("input",()=>{t!==null&&(t.currentTime=n.value)})})}document.addEventListener("DOMContentLoaded",initAudioPlayers)</script><section><div class="mt-4 prose max-w-none"><p>We continue our exploration of machine learning fundamentals with Shannon Wirtz, diving deeper into advanced model architectures, training techniques, and evaluation methods.</p><p>We start with ensemble learning - why combining multiple models often outperforms single models, and how techniques like Random Forest and XGBoost prevent overfitting through clever sampling strategies.
From there, we explore neural networks, understanding how they learn directly from raw data through sequences of linear and nonlinear transformations.</p><p>The conversation covers the evolution from convolutional neural networks (perfect for images) to recurrent neural networks (for sequences) to Transformers (the architecture behind modern LLMs).
We dive into how Transformers revolutionized natural language processing through parallelization and attention mechanisms, enabling the large language models we see today.</p><p>We then shift to the critical topic of model evaluation - exploring loss functions, gradient descent, learning rates, and the importance of proper train/validation/test splits.
Shannon explains why you need separate validation and test sets, how k-fold cross-validation works, and the various metrics used to assess model performance beyond simple accuracy.</p><p>Topics include:</p><ul><li>Ensemble learning: why combining models works (Random Forest, XGBoost)</li><li>Neural networks: linear and nonlinear transformations, neurons, and layers</li><li>Convolutional Neural Networks (CNNs): recognizing visual patterns and edges</li><li>Transformers: the architecture behind modern LLMs, attention mechanisms, and why they&rsquo;re so powerful</li><li>Training and evaluation: loss functions, gradient descent, and learning rates</li><li>Train/validation/test splits and why you need all three</li><li>K-fold cross-validation: a more robust evaluation approach</li><li>Performance metrics including precision, recall, F1 score, AUC, and the confusion matrix</li><li>Model interpretation: white box vs black box models</li><li>Interpretation techniques including partial dependence plots, SHAP values, and individual conditional expectations</li><li>Learning resources: Andrew Ng&rsquo;s courses, Kaggle, DataCamp, and hands-on projects</li></ul><p>Shannon also shares his personal learning journey, from rote learning to practical hands-on experience, and discusses how he learns most effectively through immediate feedback and engaging projects.</p><p>Whether you&rsquo;re looking to understand how modern AI systems work or seeking practical guidance on getting started with machine learning, this episode provides both theoretical depth and practical strategies for building and evaluating ML models.</p><p><em>This is Part 2 of a 2-part series. In
<a href=https://compiledconversations.com/14/ target=_blank>Part 1</a>
, we explored the foundations of machine learning - including core concepts, terminology, different learning approaches, and fundamental model types.</em></p><p><strong>Show Links</strong></p><ul><li><a href=https://www.linkedin.com/in/shannon-wirtz-a8387144/ target=_blank>Shannon Wirtz on LinkedIn</a></li><li><a href=https://en.wikipedia.org/wiki/Ensemble_learning target=_blank>Ensemble Learning</a></li><li><a href=https://en.wikipedia.org/wiki/Random_forest target=_blank>Random Forest</a></li><li><a href=https://en.wikipedia.org/wiki/XGBoost target=_blank>XGBoost</a></li><li><a href=https://en.wikipedia.org/wiki/Neural_network target=_blank>Neural Networks</a></li><li><a href=https://en.wikipedia.org/wiki/Convolutional_neural_network target=_blank>Convolutional Neural Networks</a></li><li><a href=https://github.com/deepseek-ai/DeepSeek-OCR target=_blank>DeepSeek-OCR</a></li><li><a href=https://www.image-net.org/ target=_blank>ImageNet</a></li><li><a href=https://en.wikipedia.org/wiki/AlexNet target=_blank>AlexNet</a></li><li><a href=https://en.wikipedia.org/wiki/Transformer_%28machine_learning_model%29 target=_blank>Transformers</a></li><li><a href=https://arxiv.org/abs/1706.03762 target=_blank>Attention Is All You Need</a></li><li><a href=https://en.wikipedia.org/wiki/Gradient_descent target=_blank>Gradient Descent</a></li><li><a href=https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29 target=_blank>Cross-Validation</a></li><li><a href=https://en.wikipedia.org/wiki/Precision_and_recall target=_blank>Precision and Recall</a></li><li><a href=https://en.wikipedia.org/wiki/F-score target=_blank>F1 Score</a></li><li><a href=https://en.wikipedia.org/wiki/Receiver_operating_characteristic target=_blank>AUC (Area Under Curve)</a></li><li><a href=https://en.wikipedia.org/wiki/Confusion_matrix target=_blank>Confusion Matrix</a></li><li><a href=https://shap.readthedocs.io/ target=_blank>SHAP Values</a></li><li><a href=https://scikit-learn.org/stable/modules/partial_dependence.html target=_blank>Partial Dependence Plots</a></li><li><a href=https://www.coursera.org/specializations/machine-learning-introduction target=_blank>Andrew Ng&rsquo;s Machine Learning Course</a></li><li><a href=https://www.deeplearning.ai/ target=_blank>DeepLearning.AI</a></li><li><a href=https://www.kaggle.com/ target=_blank>Kaggle</a></li><li><a href=https://www.datacamp.com/ target=_blank>DataCamp</a></li><li><a href=https://www.r-project.org/ target=_blank>R Programming Language</a></li><li><a href=https://anilananthaswamy.com/why-machines-learn target=_blank>Why Machines Learn</a></li><li><a href=https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ target=_blank>Hands-On Machine Learning</a></li><li><a href=http://neuralnetworksanddeeplearning.com/ target=_blank>Neural Networks and Deep Learning</a></li></ul></div></section></article></main><footer class="border-t border-gray-200 py-6 text-center text-gray-500 text-sm" role=contentinfo><p>&copy; 2025, <a href=https://eddmann.com target=_blank>Edd Mann</a></p></footer></div></div></body></html>